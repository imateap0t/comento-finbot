import base64
import hashlib
import streamlit as st
import sqlite3
from dotenv import load_dotenv
import os
from io import BytesIO
from langchain.text_splitter import RecursiveCharacterTextSplitter
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import letter
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
from reportlab.pdfbase import ttfonts

from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains.summarize import load_summarize_chain
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings
from langchain.document_loaders import PyPDFLoader
from langchain.chains import RetrievalQA

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY") or st.secrets["OPENAI_API_KEY"]

# LLM ì„¤ì •
llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)

# í•œê¸€ í°íŠ¸ ë“±ë¡
font_path = os.path.join(os.path.dirname(__file__), "NanumGothic-Regular.ttf")
pdfmetrics.registerFont(TTFont('NanumGothic', font_path))

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ETF ì±—ë´‡", page_icon="ğŸ’¹")
st.title("ğŸ’¹ ê¸ˆìœµ ìƒë‹´ ì±—ë´‡")
st.markdown("ê¸ˆìœµì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!")
st.markdown("")
st.markdown(
    """
    <style>
    .chat-input textarea {
        height: 3em !important;
        border-radius: 8px;
        padding: 10px;
        font-size: 1rem;
    }
    .send-button {
        background-color: #1E90FF;
        color: white;
        border-radius: 6px;
        padding: 0.5em 1.2em;
        border: none;
        cursor: pointer;
        margin-left: 10px;
    }
    .chat-row {
        display: flex;
        align-items: center;
        gap: 10px;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# ì—…ë¡œë“œ ë° ì…ë ¥
col1, col2 = st.columns([3, 1])

with col1:
    uploaded_file = st.file_uploader("ğŸ“ PDF íŒŒì¼ ì—…ë¡œë“œ", type="pdf", label_visibility="collapsed")
    st.markdown("##### ğŸ“„ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ë¬¸ì„œ ê¸°ë°˜ ì‘ë‹µì´ í™œì„±í™”ë©ë‹ˆë‹¤.")

with col2:
    use_summary = st.toggle("ìš”ì•½ë§Œ ë³´ê¸°")


# ë¬¸ì„œ ê¸°ë°˜ ì‘ë‹µ
custom_prompt = PromptTemplate.from_template("""
    ë„ˆëŠ” í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ëŠ” ê¸ˆìœµ ì „ë¬¸ê°€ì•¼.
    ë¬¸ì„œ ê¸°ë°˜ ì§ˆë¬¸ì— ëŒ€í•´ ì•„ë˜ ê¸°ì¤€ìœ¼ë¡œ ë‹µë³€í•´ì¤˜:
                                        
    1. ì§ˆë¬¸ì„ ì¶©ë¶„íˆ ì´í•´í•œ í›„ ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‹ ë¢°ì„± ìˆëŠ” ì •ë³´ ì œê³µ
    2. ì´ˆë³´ìë„ ì´í•´í•  ìˆ˜ ìˆê²Œ ì„¤ëª…
    3. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ë‹µ
    4. ìˆ˜ì¹˜, ì „ëµ, ìœ„í—˜ ìš”ì†Œ ë“±ì„ êµ¬ì²´ì ìœ¼ë¡œ í¬í•¨

ì§ˆë¬¸: {question}
---
ë‹µë³€:
""")


# --- ì´ˆê¸°í™” ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- ì—…ë¡œë“œ ì²˜ë¦¬ & ë²¡í„°ìŠ¤í† ì–´ ìºì‹œ ---
import hashlib, threading
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.retrievers.document_compressors import LLMChainExtractor
from langchain.retrievers import ContextualCompressionRetriever

@st.cache_resource(show_spinner=False)
def build_vectorstore(file_bytes: bytes):
    file_hash = hashlib.md5(file_bytes).hexdigest()
    pdf_path = f"/tmp/{file_hash}.pdf"
    with open(pdf_path, "wb") as f:
        f.write(file_bytes)
    loader = PyPDFLoader(pdf_path)
    pages = loader.load()
    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)
    docs = splitter.split_documents(pages)
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    vs = FAISS.from_documents(docs, embeddings)
    return vs, file_hash, docs

# --- ê³¼ê±° ë©”ì‹œì§€ ë Œë” ---
for m in st.session_state.messages:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

# ë¯¸ë¦¬ UI í† ê¸€
do_post = st.toggle("ìš”ì•½/ì´ë¯¸ì§€ ìƒì„± ì¼œê¸°", key="do_postprocess", value=False)

# --- ì…ë ¥ ë°›ê¸° ---
if question := st.chat_input("ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"):
    with st.chat_message("user"):
        st.markdown(question)
    st.session_state.messages.append({"role": "user", "content": question})

    pdf_mode, docs, retriever = False, None, None

    if uploaded_file:
        file_bytes = uploaded_file.read()  # í•œ ë²ˆë§Œ
        vectorstore, file_hash, docs = build_vectorstore(file_bytes)

        base_retriever = vectorstore.as_retriever(search_kwargs={"k": 3, "fetch_k": 6})
        base_retriever.search_type = "mmr"

        compressor = LLMChainExtractor.from_llm(llm)
        retriever = ContextualCompressionRetriever(
            base_compressor=compressor, base_retriever=base_retriever
        )
        pdf_mode = True
        st.markdown(
            """
            <div style="background-color:#3E3B16;padding:10px;border-radius:5px;border-left:5px solid #FFD700;">
                <strong>PDFë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.</strong>
            </div>
            """, unsafe_allow_html=True
        )
    else:
        st.markdown(
            """
            <div style="background-color:#3E3B16;padding:10px;border-radius:5px;border-left:5px solid #FFD700;">
                <strong>PDF ì—†ì´ ê¸°ë³¸ì ì¸ ê¸ˆìœµ ì •ë³´ë¥¼ ì•ˆë‚´í•©ë‹ˆë‹¤.</strong>
            </div>
            """, unsafe_allow_html=True
        )

    # --- ë‹µë³€ ìƒì„± ---
    if pdf_mode:
        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="map_reduce",
            retriever=retriever,
            chain_type_kwargs={"prompt": custom_prompt},
            return_source_documents=False,
        )
        result = qa_chain.invoke({"query": question})
        response = result["result"]
    else:
        prompt = PromptTemplate.from_template("""
            ë„ˆëŠ” ê¸ˆìœµíˆ¬ì ë¶„ì•¼ì— íŠ¹í™”ëœ AIì•¼.
            ì•„ë˜ ê¸°ì¤€ìœ¼ë¡œ í•œêµ­ì–´ë¡œë§Œ ê°„ê²°í•˜ê²Œ ë‹µí•´:
            1) ì‹ ë¢° ê°€ëŠ¥í•œ ì¶œì²˜ ê¸°ë°˜  2) ì´ˆë³´ì ìš©ì–´ í’€ì–´ì“°ê¸°  3) ìˆ˜ì¹˜/ìœ„í—˜ìš”ì†Œ í¬í•¨
            ì§ˆë¬¸: {question}
        """)
        response = llm.predict(prompt.format(question=question))

    # --- í•œ ë²ˆë§Œ ì¶œë ¥ ---
    with st.chat_message("assistant"):
        st.markdown(response)
    st.session_state.messages.append({"role": "assistant", "content": response})

    # --- ë¹„ë™ê¸° ë¡œê·¸ ---
    def log_async(q, a):
        def _w():
            conn = sqlite3.connect("chat_logs.db", check_same_thread=False)
            cur = conn.cursor()
            cur.execute("""CREATE TABLE IF NOT EXISTS chat_logs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                question TEXT, answer TEXT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
            )""")
            cur.execute("INSERT INTO chat_logs (question, answer) VALUES (?,?)", (q, a))
            conn.commit(); conn.close()
        threading.Thread(target=_w, daemon=True).start()
    log_async(question, response)

    # --- ìš”ì•½/ì›Œë“œí´ë¼ìš°ë“œ ---
    @st.cache_data(show_spinner=False)
    def summarize_once(_docs, _hash):
        # _hashë¥¼ ê°•ì œë¡œ ì½ì–´ ìºì‹œ í‚¤ë¡œ ì‚¬ìš©
        _ = str(_hash)
        chain = load_summarize_chain(llm, chain_type="map_reduce")
        return chain.run(_docs)

    if do_post and pdf_mode:
        summary = summarize_once(docs, file_hash)
        st.success(summary)

        @st.cache_data(show_spinner=False)
        def generate_wordcloud_image_cached(text, _hash):
            _ = str(_hash)
            wc = WordCloud(font_path=font_path, width=800, height=400, background_color="white").generate(text)
            buf = BytesIO(); wc.to_image().save(buf, format='PNG'); buf.seek(0); return buf
        st.image(generate_wordcloud_image_cached(summary, file_hash))

    # --- PDF ì €ì¥ ë²„íŠ¼(ì¤‘ë³µ ìš”ì•½ ì œê±°, responseë§Œ PDFë¡œ) ---
    if st.button("ğŸ¤– ë‹µë³€ì„ PDFë¡œ ì €ì¥"):
        try:
            pdf_buffer = BytesIO()
            c = canvas.Canvas(pdf_buffer, pagesize=letter)
            c.setFont('NanumGothic', 12)

            max_chars_per_line = 90
            max_lines_per_page = 40

            textobject = c.beginText(50, 750)
            textobject.setFont("NanumGothic", 12)

            lines = []
            for paragraph in response.split('\n'):
                while len(paragraph) > max_chars_per_line:
                    lines.append(paragraph[:max_chars_per_line])
                    paragraph = paragraph[max_chars_per_line:]
                lines.append(paragraph)

            line_height = 16
            y = 730
            for i, line in enumerate(lines):
                if i and i % max_lines_per_page == 0:
                    c.drawText(textobject); c.showPage()
                    textobject = c.beginText(50, 750); textobject.setFont("NanumGothic", 12)
                    y = 750
                textobject.setTextOrigin(50, y); textobject.textLine(line); y -= line_height

            c.drawText(textobject); c.save()
            st.session_state.pdf_download = pdf_buffer.getvalue()
        except Exception as e:
            st.error(f"PDF ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    # --- ë‹¤ìš´ë¡œë“œ ë§í¬/ì´ë¯¸ì§€ ---
    if "pdf_download" in st.session_state:
        b64 = base64.b64encode(st.session_state["pdf_download"]).decode()
        st.markdown(f'<a href="data:application/pdf;base64,{b64}" download="etf_response.pdf">ğŸ“„ ë‹µë³€ PDF ë‹¤ìš´ë¡œë“œ</a>', unsafe_allow_html=True)



# ì¢Œì¸¡ fAq 
with st.sidebar:
    st.markdown("## ğŸ“œ íˆ¬ì FAQ & ê°€ì´ë“œ")

    with st.expander("ğŸ“Œ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸"):
        st.markdown("""
        **1. ETFë€?**  
        ìƒì¥ì§€ìˆ˜í€ë“œë¡œ, ì§€ìˆ˜ë¥¼ ì¶”ì¢…í•˜ëŠ” í€ë“œì…ë‹ˆë‹¤. ì£¼ì‹ì²˜ëŸ¼ ê±°ë˜ë©ë‹ˆë‹¤.

        **2. ETFì™€ í€ë“œ ì°¨ì´?**  
        í€ë“œëŠ” í•˜ë£¨ 1ë²ˆ ê±°ë˜, ETFëŠ” ì‹¤ì‹œê°„ ê±°ë˜ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.

        **3. ì†Œì•¡ìœ¼ë¡œë„ ê°€ëŠ¥í•œê°€ìš”?**  
        ë„¤. ETFëŠ” 1ì£¼ ë‹¨ìœ„ë¡œ ë§¤ìˆ˜í•  ìˆ˜ ìˆì–´, ìˆ˜ì²œ ì›ìœ¼ë¡œë„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

        **4. ìˆ˜ìµë¥ ì€ ì–´ë–»ê²Œ ê³„ì‚°í•˜ë‚˜ìš”?**  
        (í˜„ì¬ê°€ - ë§¤ìˆ˜ê°€) / ë§¤ìˆ˜ê°€ Ã— 100
        """)

    with st.expander("ğŸ’¡ ì´ˆë³´ìë¥¼ ìœ„í•œ íˆ¬ì ê°œë…"):
        st.markdown("""
        **ğŸ“ ë¶„ì‚° íˆ¬ì**  
        ì—¬ëŸ¬ ìì‚°ì— ë‚˜ëˆ„ì–´ íˆ¬ìí•¨ìœ¼ë¡œì¨ ë¦¬ìŠ¤í¬ë¥¼ ì¤„ì´ëŠ” ì „ëµì…ë‹ˆë‹¤.

        **ğŸ“ ë¦¬ìŠ¤í¬ë€?**  
        ìˆ˜ìµì´ ë“¤ì­‰ë‚ ì­‰í•˜ê±°ë‚˜ ì†ì‹¤ì´ ë‚  ê°€ëŠ¥ì„±ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

        **ğŸ“ ETF ì¥ì **  
        - ë¶„ì‚° íˆ¬ì íš¨ê³¼
        - ë‚®ì€ ìˆ˜ìˆ˜ë£Œ
        - ë‹¤ì–‘í•œ ìì‚°êµ°(ì£¼ì‹, ì±„ê¶Œ, ê¸ˆ ë“±)

        **ğŸ“ ì¥ê¸° íˆ¬ìë€?**  
        ë‹¨ê¸° ì‹œì„¸ ë³€ë™ì— í”ë“¤ë¦¬ì§€ ì•Šê³  ì¼ì • ê¸°ê°„ ì´ìƒ ë³´ìœ í•˜ì—¬ ìˆ˜ìµì„ ê¸°ëŒ€í•˜ëŠ” ì „ëµì…ë‹ˆë‹¤.
        """)

